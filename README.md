# ETL Engineering
## Scenario
For this project, we assume the role of data engineer working for an international financial analysis company. Our company tracks stock prices, commodities, forex rates, inflation rates.  Our job is to extract financial data from various sources like websites, APIs and files provided by various financial analysis firms. After  collecting the data, we extract the data of interest to our company and transform it based on the given requirements. Once the transformation is complete we load that data into a database.
## Project Tasks

2. **Collect Data Using Web Scraping:**
   - Extract data from websites using web scraping techniques.

3. **Download Files to Process:**
   - Download relevant files that need to be processed as part of the data pipeline.

4. **Read CSV, XML, and JSON File Types:**
   - Load data from different file formats, including CSV, XML, and JSON.

5. **Extract Data from the Above File Types:**
   - Extract and structure data obtained from various file formats.

6. **Transform Data:**
   - Clean, filter, aggregate, and transform the data to make it suitable for analysis.

7. **Use the Built-In Logging Module:**
   - Implement logging to track the progress and activities during the ETL process.

8. **Save the Transformed Data:**
   - Store the processed and transformed data in a format that data engineers can use for loading.

## Getting Started

To get started with the project, follow these steps:

1. Clone this repository to your local machine.

2. Install any required dependencies by running:
   ```
   pip install -r requirements.txt
   ```

3. Begin implementing the ETL pipeline by working on each of the project tasks.

## Contributing

Contributions are welcome! If you find any issues or want to add improvements to the project, feel free to submit a pull request.

## License

This project is licensed under the [MIT License](LICENSE).

Happy ETL Engineering!
